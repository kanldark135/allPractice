{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 머신러닝 Process </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_names = iris.feature_names\n",
    "iris_label = iris.target\n",
    "\n",
    "df_iris = pd.DataFrame(data = iris_data, columns = iris_names)\n",
    "df_iris['label'] = iris_label\n",
    "\n",
    "df_iris.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size = 0.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clf = DecisionTreeClassifier(random_state = 11)\n",
    "df_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = df_clf.predict(X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, pred) # y_test = 실제 y test값 / pred = 학습된 모델이 y_train 으로 추정한 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Dataset 관련 </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# load_iris() -> 분류 / load_breast_cancer() -> 분류 / load_diabetes() -> 회귀 / load_digits() -> 분류\n",
    "\n",
    "# 각각은 data / target / target_names / feature_names 로 구성된 dict 임\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> <b style = \"color:Blue;\"> sklearn.model_selection </b> : 학습 데이터와 테스트 데이터 구분 </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import <b style = \"color:red;\"> train_test_split </b>\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, params : {test_size = 0.3 , shuffle = True, random_state = seed_number})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 1. prepare data\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_features = iris.feature_names\n",
    "iris_label = iris.target\n",
    "\n",
    "df_iris = pd.DataFrame(data = iris_data, columns = iris_features)\n",
    "df_iris['target'] = iris_label\n",
    "\n",
    "# 2. train_test_split\n",
    "df_train = df_iris.iloc[:, :-1]\n",
    "df_target = df_iris.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train, df_target, test_size = 0.3, shuffle = True)\n",
    "# shuffle 이 true 이므로 할때마다 train/test 셋이 달라지고 그에 따라 모델도 달라짐\n",
    "\n",
    "# 3. declare specific model\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# 4. fit train data to model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 5. predict from test data\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# 6. evaluate the result of prediction\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 교차검증 </h3>\n",
    "데이터셋 -> 학습 데이터 / 테스트 데이터\n",
    "이를 다시 재차 데이터셋 -> 학습 데이터 / 검증 데이터 / 테스트 데이터로 나눔\n",
    "(통상 주어진 데이터셋으로는 8:1:1로 쪼개서 test 데이터는 마지막까지 건드리지 말고/ 이상적으로는 8:2로 학습/검증 실시 후 test 데이터는 아예 외부에서 가져온 새 데이터 사용)\n",
    "\n",
    "검증을 하는 이유는\n",
    "검증 없이 학습 데이터셋 한번만으로 모델을 도출하면 이는 1회 학습에 의한 모델로 끝남\n",
    "여러번의 학습을 통해 여러 모델을 도출하여 모델의 신뢰성, 예측력 증대 및 하이퍼파라미터 튜닝 가능\n",
    "\n",
    "과정\n",
    "1) 데이터를 쪼개고 2) 데이터셋을 shuffle 시켜서 여러 조합의 (학습, 검증) 데이터셋을 다시 구성\n",
    "* Kfold는 index 기준으로 나눔 : 1-100개의 학습데이터인 경우\n",
    "(학습, 검증)\n",
    "1회차 : (21-100, 1-20)\n",
    "2회차 : (1-20 + 41-100, 21-40)\n",
    "3회차 : (1-40 + 61-100, 41-60)\n",
    "...\n",
    "\n",
    "1회 모델 : 학습 데이터1 을 fit 시킨 모델에 대한 pred 검증 데이터1 및 metric 측정\n",
    "2회 모델 : 학습 데이터2 을 fit 시킨 모델에 대한 pred 검증 데이터2 및 metric 측정\n",
    "3회 모델....\n",
    "\n",
    "이렇게 n개의 (학습, 검증) 조합에 대한 모델을 도출해놓고\n",
    "-> 최종 모델을 평균 등으로 도출하여\n",
    "\n",
    "도출된 모델에 대해 최종적으로 test 셋에 대해서 실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 이제부터 머신러닝적 용어로 사용 : x값 = data => features / y값 = target => label\n",
    "\n",
    "# 1. prepare data\n",
    "iris = load_iris()\n",
    "iris_features = iris.data\n",
    "iris_feature_names = iris.feature_names\n",
    "iris_label = iris.target\n",
    "\n",
    "df_iris = pd.DataFrame(data = iris_features, columns = iris_feature_names)\n",
    "df_iris['target'] = iris_label\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits= 5)\n",
    "cv_accuracy = []\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "n_iter = 0\n",
    "for train_index, valid_index in kfold.split(iris_features):\n",
    "    X_train, X_valid = iris_features[train_index], iris_features[valid_index]\n",
    "    y_train, y_valid = iris_label[train_index], iris_label[valid_index]\n",
    "\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_valid)\n",
    "    n_iter += 1\n",
    "\n",
    "    accuracy = accuracy_score(y_valid, pred)\n",
    "\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "np.mean(cv_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified KFold\n",
    "\n",
    "기존 KFold 의 경우 train/valid set 을 나누는 기준이 그냥 dataset 의 나열된 순서대로임\n",
    "\n",
    "stratified fold 는 데이터셋의 라벨별로 숫자 맞춰서 쪼개서 학습시킴\n",
    "\n",
    "예) 라벨1 50개 라벨2 50개 라벨3 50개가 임의로 섞여있다고 할때,\n",
    "\n",
    "kfold 는 아무런 고려 없이 순서대로 쪼개면 어쩌다 보면 검증셋에 라벨 1만 30개가 뭉쳐져 있을 수도 있음 (특정 학습셋에서 라벨1이 부족한 모델이 도출될 수 있음)\n",
    "skf 는 학습데이터 : 라벨1 40/라벨2 40/라벨3 40개 / 검증데이터 : 라벨1 10/라벨2 10/라벨3 10 가 되게끔 데이터를 쪼개줌\n",
    "(다만 stratified 된 각각의 fold 내에서는 다시 순서대로 쪼갬)\n",
    "\n",
    "예)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9733333333333333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 이제부터 머신러닝적 용어로 사용 : x값 = data => features / y값 = target => label\n",
    "\n",
    "# 1. prepare data\n",
    "\n",
    "iris = load_iris()\n",
    "iris_features = iris.data\n",
    "iris_feature_names = iris.feature_names\n",
    "iris_label = iris.target\n",
    "\n",
    "df_iris = pd.DataFrame(data = iris_features, columns = iris_feature_names)\n",
    "df_iris['target'] = iris_label\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 1) 학습데이터를 재차 학습/검증으로 쪼개고 / \n",
    "# 2) for loop 으로 각각의 데이터에 대한 학습과 예측 수행하여 / \n",
    "# 3) 개별 결과를 평균하여 최종 모델\n",
    "\n",
    "skf = StratifiedKFold(n_splits= 5)\n",
    "cv_accuracy = []\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "n_iter = 0\n",
    "for train_index, valid_index in skf.split(df_iris, iris_label):\n",
    "    X_train, X_valid = iris_features[train_index], iris_features[valid_index]\n",
    "    y_train, y_valid = iris_label[train_index], iris_label[valid_index]\n",
    "\n",
    "    print(f\"train_index : {train_index}\")\n",
    "    print(f\"test_index : {valid_index}\")\n",
    "\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    pred = rf_clf.predict(X_valid)\n",
    "    n_iter += 1\n",
    "\n",
    "    accuracy = accuracy_score(y_valid, pred)\n",
    "\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "np.mean(cv_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> cross_val_score </h3>\n",
    "<p> 위에 수행한 일련의 작업 </p>\n",
    "데이터셋에서 -> 1) 학습 데이터와 검증데이터 쪼개고 / 2) 각 데이터셋으로 모델 학습 후 / 3) 각 (학습, 검증) 에 대한 모델의 평균적인 metric 까지 판단<p/> -> 교차검증 작업\n",
    "\n",
    "-> crossl_val_score(사용 알고리즘, 피쳐, 라벨, scoring = , cv = ) 로 한번에 수행 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92592593 0.85185185 0.96296296 0.92592593 1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋 정리\n",
    "iris = load_iris()\n",
    "feature = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# 학습데이터 / 테스트데이터 분해\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature, label, test_size = 0.1, shuffle = True)\n",
    "\n",
    "#위에 3가지 작업(학습데이터 -> 학습/검증 -> 복수의 서로 다른 학습/검증 생성 (skf) -> 학습train/검증test 결과 정리) 순식간에\n",
    "scores = cross_val_score(dt_clf, X_train, y_train, scoring = 'accuracy', cv = 5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> GridSearchCV : 위의 cross_val_score 의 교차검증작업에 더해서 사용하는 데이터셋을 활용한 학습시 모델의 최적 파라메터까지 찾아서 머신러닝 모델 만들어주는 역할 </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적파라메터  {'max_depth': 3, 'min_samples_split': 2}\n",
      "최고정확도  0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# 특정 머신러닝 모델의 하이퍼파라메터들의 조합 (모델마다 다름. 꼭 list 형태로)\n",
    "\n",
    "params = {'max_depth' : [1, 2, 3], 'min_samples_split' : [2, 3]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_dtree = GridSearchCV(dt_clf, param_grid = params, cv = 3, refit = True, return_train_score = True)\n",
    "# refit = True 하면 바로 밑에서 grid_dtree.fit 시킬때 자동으로 best estimating params 으로 fit 시킴\n",
    "\n",
    "grid_dtree.fit(X_train, y_train) # best result param 으로 fit\n",
    "\n",
    "# 일단 (학습/검증) 결과 정리\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "print(\"최적파라메터 \", grid_dtree.best_params_)\n",
    "print(\"최고정확도 \", grid_dtree.best_score_)\n",
    "\n",
    "# 테스트데이터에 최종 \n",
    "pred = grid_dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 데이터 전처리 방법 - 인코딩 </h3>\n",
    "(범주) 데이터를 모델에 쓰기 적합한 값으로 변환해주는 작업<p/>\n",
    "<ul>\n",
    "    <li> 레이블 인코딩\n",
    "    <li> 원 핫 인코딩\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TV' '냉장고' '믹서기' '선풍기' '전자렌지' '컴퓨터']\n",
      "['전자렌지' '컴퓨터' '믹서기' 'TV' '냉장고' '냉장고' '선풍기']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', '냉장고', '전자렌지', '컴퓨터', '선풍기', '선풍기', '믹서기', '믹서기']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "labels = encoder.fit_transform(items)\n",
    "print(encoder.classes_)\n",
    "print(encoder.inverse_transform([4,5,2,0,1,1,3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_TV</th>\n",
       "      <th>item_냉장고</th>\n",
       "      <th>item_믹서기</th>\n",
       "      <th>item_선풍기</th>\n",
       "      <th>item_전자렌지</th>\n",
       "      <th>item_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_TV  item_냉장고  item_믹서기  item_선풍기  item_전자렌지  item_컴퓨터\n",
       "0        1         0         0         0          0         0\n",
       "1        0         1         0         0          0         0\n",
       "2        0         0         0         0          1         0\n",
       "3        0         0         0         0          0         1\n",
       "4        0         0         0         1          0         0\n",
       "5        0         0         0         1          0         0\n",
       "6        0         0         1         0          0         0\n",
       "7        0         0         1         0          0         0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "items = ['TV', '냉장고', '전자렌지', '컴퓨터', '선풍기', '선풍기', '믹서기', '믹서기']\n",
    "item_array = np.array(items).reshape(-1, 1)\n",
    "\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(item_array)\n",
    "oh_labels = oh_encoder.transform(item_array)\n",
    "\n",
    "print(oh_labels.toarray())\n",
    "\n",
    "# 동일한 방법으로 그냥 reshape, encoder 같은거 안 쓰고 데이터프레임으로 처리\n",
    "\n",
    "df_items = pd.DataFrame(data = items, columns = ['item'])\n",
    "pd.get_dummies(df_items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리 방법 - 스케일링\n",
    "\n",
    "1) 표준화 : 평균이 0, 표준편차가 1인 정규분포로 변환 : 정규화식\n",
    "StandardScaler\n",
    "2) 정규화 : 최대값 - 최소값 범위에 대한 (0, 1) 사이의 값으로 변환 = 값 - 최소값 / (최대값 - 최소값)\n",
    "MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_features = iris.data\n",
    "iris_feature_names = iris.feature_names\n",
    "iris_label = iris.target\n",
    "df_iris = pd.DataFrame(iris_features, columns = iris_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df_iris)\n",
    "\n",
    "df_iris_scaled = scaler.transform(df_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit - transfrom 적용할때 유의사항 : 학습 데이터랑 테스트 데이터에 대해서 따로따로 fit 적용하면 안됨\n",
    "스케일링을 하려면 데이터 모든 값에 대해 동일한 방법을 적용해야 하므로\n",
    "\n",
    "scaler.fit(train_array)\n",
    "scaled_train = scaler.transfrom(train_array)\n",
    "\n",
    "이후\n",
    "\n",
    "scaler.fit(test_array)\n",
    "scaled_test = scaler.transform(test_array) 가 아니라\n",
    "\n",
    "그냥 기존에 train_array에 fit 해놓은 그대로 transform 만 해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. ]\n",
      " [0.1]\n",
      " [0.2]\n",
      " [0.3]\n",
      " [0.4]\n",
      " [0.5]\n",
      " [0.6]\n",
      " [0.7]\n",
      " [0.8]\n",
      " [0.9]\n",
      " [1. ]]\n",
      "[[0. ]\n",
      " [0.2]\n",
      " [0.4]\n",
      " [0.6]\n",
      " [0.8]\n",
      " [1. ]]\n",
      "[[0. ]\n",
      " [0.1]\n",
      " [0.2]\n",
      " [0.3]\n",
      " [0.4]\n",
      " [0.5]\n",
      " [0.6]\n",
      " [0.7]\n",
      " [0.8]\n",
      " [0.9]\n",
      " [1. ]]\n",
      "[[0. ]\n",
      " [0.1]\n",
      " [0.2]\n",
      " [0.3]\n",
      " [0.4]\n",
      " [0.5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train_array = np.arange(0, 11).reshape(-1, 1)\n",
    "test_array = np.arange(0, 6).reshape(-1, 1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 부정확한 scaling : train 값과 test 값을 서로 다른 scaling 적용\n",
    "\n",
    "scaler.fit(train_array)\n",
    "scaled_train = scaler.transform(train_array)\n",
    "scaler.fit(test_array)\n",
    "scaled_test = scaler.transform(test_array)\n",
    "\n",
    "print(scaled_train)\n",
    "print(scaled_test)\n",
    "\n",
    "# 맞는 scaling : train 값과 test 값에 동일한 scaling 기준 적용\n",
    "\n",
    "scaler.fit(train_array)\n",
    "scaled_train = scaler.transform(train_array)\n",
    "scaled_test = scaler.transform(test_array)\n",
    "\n",
    "print(scaled_train)\n",
    "print(scaled_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 중간프로젝트 : 타이타닉 분석 </h2>\n",
    "\n",
    "- 데이터 전처리\n",
    "- 모델 학습\n",
    "- 검증/예측\n",
    "- 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 확보\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv(\"./titanic_train.csv\")\n",
    "df_test = pd.read_csv(\"./titanic_test.csv\")\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 Overview \n",
    "\n",
    "df_train.info() # null값 유무 / 데이터타입 체크\n",
    "df_train.describe() # 대략적인 통계 (평균, 표준편차, Percentile 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    False\n",
       "Survived       False\n",
       "Pclass         False\n",
       "Name           False\n",
       "Sex            False\n",
       "Age            False\n",
       "SibSp          False\n",
       "Parch          False\n",
       "Ticket         False\n",
       "Fare           False\n",
       "Cabin          False\n",
       "Embarked       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리 1 : null값 처리\n",
    "\n",
    "df_train['Age'] = df_train['Age'].fillna(df_train['Age'].mean())\n",
    "df_train['Cabin'] = df_train['Cabin'].fillna('N')\n",
    "df_train['Embarked'] = df_train['Embarked'].fillna('N')\n",
    "\n",
    "df_train.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Survived\n",
       "female  0            81\n",
       "        1           233\n",
       "male    0           468\n",
       "        1           109\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(['Sex', 'Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Age_cat', ylabel='Survived'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 정리 및 시각화 2.\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "group_names = ['Baby', 'Teen', 'Young', 'Young_Adult', 'Adult', 'Old']\n",
    "\n",
    "def age_categorization(age):\n",
    "    res = 0\n",
    "    if age < 5 : res = \"Baby\"\n",
    "    elif age < 15 : res = \"Teen\"\n",
    "    elif age < 25 : res = \"Young\"\n",
    "    elif age < 35 : res = \"Young Adult\"\n",
    "    elif age < 60 : res = \"Adult\"\n",
    "    else : res = \"Old\"\n",
    "    return res\n",
    "\n",
    "df_train['Age_cat'] = df_train['Age'].apply(age_categorization)\n",
    "\n",
    "sns.barplot(x = 'Age_cat', y = 'Survived', hue = 'Sex', data = df_train, order = group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_cat</th>\n",
       "      <th>Cabin_labeled</th>\n",
       "      <th>Sex_labeled</th>\n",
       "      <th>Embarked_labeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>Young</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Adult</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Adult</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>Adult</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked      Age_cat  \\\n",
       "0      0         A/5 21171   7.2500     N        S        Young   \n",
       "1      0          PC 17599  71.2833   C85        C        Adult   \n",
       "2      0  STON/O2. 3101282   7.9250     N        S  Young Adult   \n",
       "3      0            113803  53.1000  C123        S        Adult   \n",
       "4      0            373450   8.0500     N        S        Adult   \n",
       "\n",
       "   Cabin_labeled  Sex_labeled  Embarked_labeled  \n",
       "0            146            1                 3  \n",
       "1             81            0                 0  \n",
       "2            146            0                 3  \n",
       "3             55            0                 3  \n",
       "4            146            1                 3  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 인코딩\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_features(df):\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    for feature in features:\n",
    "        le.fit(df[feature])\n",
    "        df[f\"{feature}_labeled\"] = le.transform(df[feature])\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = encode_features(df_train)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b3 style = \"font-size:20pt;color:blue;\"> 상기 내용 정리 </b3>\n",
    "\n",
    "<ol>\n",
    "    <li> 데이터 수집 > DataFrame 생성 : <b>df_original</b>\n",
    "    <li> 데이터의 feature 와 label 나눠서 식별\n",
    "    <li> 데이터 전처리\n",
    "            nan 값 메꾸기 \n",
    "            실제 전처리 : preprocessing\n",
    "                범주변수 : .LabelEncoder / .OnehotEncoder / \n",
    "                양적변수 : .StandardScaler / .MinMaxScaler\n",
    "                * 특정 피처(df에서는 컬럼) 에 대해서 필요한 부분만 loop 로 처리하는 관행\n",
    "                for feature in features:\n",
    "                    le = pre.LabelEncoder()\n",
    "                    le.fit(df[feature])\n",
    "                    df[feature] = le.transform(df[feature])\n",
    "            필요없는 피처는 정리\n",
    "    <li> 전처리된 데이터를 학습 데이터와 테스트 데이터로 분리 : X_train, X_test, Y_train, Y_test = model_selection.train_test_split\n",
    "    <li> 학습 데이터를 재차 학습 데이터 / 검증 데이터로 분리 : model_selection.KFold\n",
    "    <li> 각각의 (학습, 검증) 셋에 대한 머신러닝 모델의 결과 수집\n",
    "        for train_index, valid_index in KFold.split(df_train):\n",
    "            x_train = X_train[train_index], y_train = Y_train(train_index)\n",
    "            x_valid = X_train(valid_index), y_valid = Y_train(valid_index)\n",
    "            model.fit(x_train, y_train)\n",
    "            pred = model.predict()\n",
    "            metric = 어떤 metric(pred)\n",
    "\n",
    "            metric 의 평균치를 가지고 해당 모델의 적합도 판단\n",
    "\n",
    "        해당 과정을 cross_val_score (모델, X_train, Y_train, cv = ) 함수로 한번에 해결 가능 (학습/검증 분리 -> 모델 fit -> 모델들의 평균 스코어 산출)\n",
    "\n",
    "    <li> 교차검증결과가 충분히 괜찮다면, 최종 predict 실시\n",
    "        model.fit(X_train, Y_train)\n",
    "        model.predict(X_test)\n",
    "    \n",
    "</ol>\n",
    "\n",
    "    해당 과정을 GridSearchCV 로 하이퍼파라메터 최적화까지 실시 가능\n",
    "    \n",
    "    param_array = {'a' : [1,2,3,4....], 'b' : [3,4,5,6,...]}\n",
    "\n",
    "    grid_모델명 = GridSearchCV(모델, param_grid = param_array, cv = 5, scoring = \"특정 metric\", refit = True, return_train_score = True =)\n",
    "    grid_모델명.fit(X_train, Y_train)\n",
    "    grid_모델명.predict()\n",
    "\n",
    "    -> 학습/검증 분리 -> 모델 fit하면서 최적 파라메터까지 전부 검색하는 카테시안 곱의 가짓수 (학습/검증 개수 X 파라메터1 개수 X 파라메터2 개수.... 의 모델 fitting 하여 highest metric 모델 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상기 내용 정리\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# path = os.getcwd()\n",
    "path = os.getcwd() + \"//머신러닝_강의\"\n",
    "\n",
    "# 공부 목적으로 그냥 합쳐버림\n",
    "\n",
    "df_train = pd.read_csv(path + \"/titanic_train.csv\")\n",
    "df_test = pd.read_csv(path + \"/titanic_test.csv\")\n",
    "\n",
    "# 1) df 에서 x값(feature) / y값(label) 쪼개기\n",
    "y_df_train = df_train[['Survived']]\n",
    "X_df_train = df_train.drop(columns = ['Survived'])\n",
    "\n",
    "def fill_na(df): # nan값 메꾸기\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace = True)\n",
    "    df['Cabin'].fillna(\"N\", inplace = True)\n",
    "    df['Embarked'].fillna('N', inplace = True)\n",
    "    return df\n",
    "\n",
    "def drop_features(df): # 필요 없는 피쳐는 삭제\n",
    "    df.drop(columns = ['PassengerId', 'Name', 'Ticket'], inplace = True)\n",
    "    return df\n",
    "\n",
    "def encode_features(df): # string 형태의 범주변수들은 encoding 하여 바꿔준다.\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    cat_features = ['Cabin', 'Sex', 'Embarked']\n",
    "\n",
    "    for feature in cat_features:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "\n",
    "    return df\n",
    "\n",
    "# 상기 함수를 encompass 하는 container 함수\n",
    "\n",
    "def preprocess(df):\n",
    "    df = fill_na(df)\n",
    "    df = drop_features(df)\n",
    "    df = encode_features(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "X_df_train = preprocess(X_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 8) (179, 8) (712, 1) (179, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df_train, y_df_train , test_size = 0.2, random_state = 11)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanld\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8044692737430168 0.8379888268156425 0.8491620111731844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanld\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kanld\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 여러 모델로 테스트\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "rf_clf = RandomForestClassifier()\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "dt_clf_score = accuracy_score(y_test, dt_pred)\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "rf_clf_score = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "lr_clf_score = accuracy_score(y_test, lr_pred)\n",
    "\n",
    "print(dt_clf_score, rf_clf_score, lr_clf_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습데이터를 검증데이터 추가하여 Kfold\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#1. linearly selected Kfold\n",
    "\n",
    "def kfold_validate(model, kfold_num = 5):\n",
    "    scores = {}\n",
    "    kfold = KFold(kfold_num)\n",
    "    \n",
    "    for iter_count, (train_index, valid_index) in enumerate(kfold.split(X_df_train)):\n",
    "        X_train, y_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_test, y_test = X_train.iloc[valid_index], y_train.iloc[valid_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_test)\n",
    "        model_score = accuracy_score(y_test, pred)\n",
    "        scores[f\"{model}_{iter_count}\"] = model_score\n",
    "\n",
    "    return scores\n",
    "\n",
    "# 2. 위에 한 거 그냥 cross_val_score 로 한번에 (kfold는 stratified kfold 자동으로)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(dt_clf, X_train, y_train, cv = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DecisionTreeClassifier()_0': 0.7541899441340782, 'DecisionTreeClassifier()_1': 0.7808988764044944, 'DecisionTreeClassifier()_2': 0.7865168539325843, 'DecisionTreeClassifier()_3': 0.7584269662921348, 'DecisionTreeClassifier()_4': 0.8314606741573034}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.73743017, 0.76966292, 0.80337079, 0.76966292, 0.8258427 ])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(kfold_validate(dt_clf, 5))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼파라메터 : {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "최고 점수 : 0.7991825076332119\n",
      "최적 하이퍼파라메터 : 12\n",
      "0.8715083798882681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'max_depth' : [2,3,5,10],\n",
    "    'min_samples_split' : [2,3,5],\n",
    "    'min_samples_leaf' : [1,5,8]\n",
    "}\n",
    "\n",
    "grid_dt_clf = GridSearchCV(dt_clf, param_grid = params, scoring = 'accuracy', cv = 5, refit = True)\n",
    "\n",
    "grid_dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# 여러 메서드\n",
    "\n",
    "print(\"최적 하이퍼파라메터 :\", grid_dt_clf.best_params_)\n",
    "print(\"최고 점수 :\", grid_dt_clf.best_score_)\n",
    "print(\"최적 하이퍼파라메터 :\", grid_dt_clf.best_index_)\n",
    "\n",
    "pred = grid_dt_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개인 실습\n",
    "\n",
    "#1. 데이터 수집\n",
    "#2. 데이터 전처리\n",
    "#3. 데이터 피처/라벨 분리 \n",
    "#4. 데이터 학습 / 테스트 분리\n",
    "#5. 교차검증목적 분리\n",
    "#6. 모델 fit (하이퍼파라메터 등) \n",
    "#7. 테스트에 대한 측정\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_data = pd.read_csv(\"C:/Users/kanld/Desktop/allPractice/머신러닝_강의/titanic_train.csv\")\n",
    "\n",
    "# 전처리 : 전처리 모듈 생성\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def fill_na(df_column):\n",
    "    try:\n",
    "        df_column = df_column.fillna(df_column.mean())\n",
    "    except:\n",
    "        df_column = df_column.fillna(method = 'ffill')\n",
    "    return df_column\n",
    "\n",
    "def encoding_cat_feature(feature_array):\n",
    "    lb = LabelEncoder()\n",
    "    lb.fit(feature_array)\n",
    "    res = lb.transform(feature_array)\n",
    "    return res\n",
    "\n",
    "def cabin_first_word(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    return df\n",
    "\n",
    "def needed_data_only(df, column_list:list):\n",
    "    df = df[column_list]\n",
    "    return df\n",
    "\n",
    "def preprocess(df, encoding_list = ['Sex', 'Cabin', 'Embarked']):\n",
    "    df['Cabin'].fillna(\"N\", inplace = True)\n",
    "    df = needed_data_only(df, column_list = ['Pclass', 'Survived', 'Sex', 'Age', 'Cabin', 'Embarked'])\n",
    "    df = df.apply(fill_na, axis = 0)\n",
    "    df = cabin_first_word(df)\n",
    "    df[encoding_list] = df[encoding_list].apply(encoding_cat_feature)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_data = preprocess(df_data)\n",
    "\n",
    "# 피처, 라벨 분리\n",
    "\n",
    "df_feature = df_data.drop(columns = ['Survived'])\n",
    "df_label = df_data[['Survived']]\n",
    "\n",
    "# 학습, 테스트 분리\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_feature, df_label, test_size = 0.2)\n",
    "\n",
    "# 5,6 + 파라메터 최적화 한번에\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "params = {\n",
    "    'max_depth' : [2,3,5,10],\n",
    "    'min_samples_split' : [2,3,5],\n",
    "    'min_samples_leaf' : [1,5,8]\n",
    "}\n",
    "\n",
    "grid_dt_clf = GridSearchCV(dt_clf, param_grid = params, scoring = 'accuracy', cv = 5, refit = True, return_train_score = True)\n",
    "\n",
    "grid_dt_clf.fit(X_train, Y_train)\n",
    "\n",
    "pred = grid_dt_clf.predict(X_test)\n",
    "\n",
    "# 7. 검증\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score = accuracy_score(Y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b3 style = \"font-size:20pt;color:blue;\"> 상기 내용 정리 </b3>\n",
    "\n",
    "<ol>\n",
    "    <li> 데이터 수집 > DataFrame 생성 : <b>df_original</b>\n",
    "    <li> 데이터의 feature 와 label 나눠서 식별\n",
    "    <li> 데이터 전처리\n",
    "            nan 값 메꾸기 \n",
    "            실제 전처리 : preprocessing\n",
    "                범주변수 : .LabelEncoder / .OnehotEncoder / \n",
    "                양적변수 : .StandardScaler / .MinMaxScaler\n",
    "                * 특정 피처(df에서는 컬럼) 에 대해서 필요한 부분만 loop 로 처리하는 관행\n",
    "                for feature in features:\n",
    "                    le = pre.LabelEncoder()\n",
    "                    le.fit(df[feature])\n",
    "                    df[feature] = le.transform(df[feature])\n",
    "            필요없는 피처는 정리\n",
    "    <li> 전처리된 데이터를 학습 데이터와 테스트 데이터로 분리 : X_train, X_test, Y_train, Y_test = model_selection.train_test_split\n",
    "    <li> 학습 데이터를 재차 학습 데이터 / 검증 데이터로 분리 : model_selection.KFold\n",
    "    <li> 각각의 (학습, 검증) 셋에 대한 머신러닝 모델의 결과 수집\n",
    "        for train_index, valid_index in KFold.split(df_train):\n",
    "            x_train = X_train[train_index], y_train = Y_train(train_index)\n",
    "            x_valid = X_train(valid_index), y_valid = Y_train(valid_index)\n",
    "            model.fit(x_train, y_train)\n",
    "            pred = model.predict()\n",
    "            metric = 어떤 metric(pred)\n",
    "\n",
    "            metric 의 평균치를 가지고 해당 모델의 적합도 판단\n",
    "\n",
    "        해당 과정을 cross_val_score (모델, X_train, Y_train, cv = ) 함수로 한번에 해결 가능 (학습/검증 분리 -> 모델 fit -> 모델들의 평균 스코어 산출)\n",
    "\n",
    "    <li> 교차검증결과가 충분히 괜찮다면, 최종 predict 실시\n",
    "        model.fit(X_train, Y_train)\n",
    "        model.predict(X_test)\n",
    "    \n",
    "</ol>\n",
    "\n",
    "    해당 과정을 GridSearchCV 로 하이퍼파라메터 최적화까지 실시 가능\n",
    "    \n",
    "    param_array = {'a' : [1,2,3,4....], 'b' : [3,4,5,6,...]}\n",
    "\n",
    "    grid_모델명 = GridSearchCV(모델, param_grid = param_array, cv = 5, scoring = \"특정 metric\", refit = True, return_train_score = True =)\n",
    "    grid_모델명.fit(X_train, Y_train)\n",
    "    grid_모델명.predict()\n",
    "\n",
    "    -> 학습/검증 분리 -> 모델 fit하면서 최적 파라메터까지 전부 검색하는 카테시안 곱의 가짓수 (학습/검증 개수 X 파라메터1 개수 X 파라메터2 개수.... 의 모델 fitting 하여 highest metric 모델 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
